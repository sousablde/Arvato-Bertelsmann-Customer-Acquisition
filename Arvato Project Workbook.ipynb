{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#imports to help me plot my venn diagrams\n",
    "import matplotlib_venn as venn2\n",
    "from matplotlib_venn import venn2\n",
    "from pylab import rcParams\n",
    "\n",
    "# import the util.py file where I define my functions\n",
    "from utils import *\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "'''\n",
    "There are 2 warnings when we read in the datasets:\n",
    "DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "interactivity=interactivity, compiler=compiler, result=result)\n",
    "\n",
    "This warning happens when pandas attempts to guess datatypes on particular columns, I will address this on \n",
    "the pre-processing steps\n",
    "'''\n",
    "azdias = pd.read_csv(r\"C:\\Users\\sousa\\Desktop\\github\\Arvato\\data\\azdias.csv\")\n",
    "customers = pd.read_csv(r\"C:\\Users\\sousa\\Desktop\\github\\Arvato\\data\\customers.csv\")\n",
    "attributes = pd.read_csv(r\"C:\\Users\\sousa\\Desktop\\github\\Arvato\\data\\features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CAMEO_DEUG_2015', 'CAMEO_INTL_2015'], dtype='object')\n",
      "Index(['CAMEO_DEUG_2015', 'CAMEO_INTL_2015'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# I will now check what is the problem with the columns 19 and 20\n",
    "# getting the name of these columns\n",
    "print(azdias.iloc[:,19:21].columns)\n",
    "print(customers.iloc[:,19:21].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 8.0 4.0 2.0 6.0 1.0 9.0 5.0 7.0 3.0 '4' '3' '7' '2' '8' '9' '6' '5'\n",
      " '1' 'X']\n",
      "[nan 51.0 24.0 12.0 43.0 54.0 22.0 14.0 13.0 15.0 33.0 41.0 34.0 55.0 25.0\n",
      " 23.0 31.0 52.0 35.0 45.0 44.0 32.0 '22' '24' '41' '12' '54' '51' '44'\n",
      " '35' '23' '25' '14' '34' '52' '55' '31' '32' '15' '13' '43' '33' '45'\n",
      " 'XX']\n",
      "[1.0 nan 5.0 4.0 7.0 3.0 9.0 2.0 6.0 8.0 '6' '3' '8' '9' '2' '4' '1' '7'\n",
      " '5' 'X']\n",
      "[13.0 nan 34.0 24.0 41.0 23.0 15.0 55.0 14.0 22.0 43.0 51.0 33.0 25.0 44.0\n",
      " 54.0 32.0 12.0 35.0 31.0 45.0 52.0 '45' '25' '55' '51' '14' '54' '43'\n",
      " '22' '15' '24' '35' '23' '12' '44' '41' '52' '31' '13' '34' '32' '33'\n",
      " 'XX']\n"
     ]
    }
   ],
   "source": [
    "# checking the unique values in these columns for possible issues\n",
    "print(azdias.CAMEO_DEUG_2015.unique())\n",
    "print(azdias.CAMEO_INTL_2015.unique())\n",
    "print(customers.CAMEO_DEUG_2015.unique())\n",
    "print(customers.CAMEO_INTL_2015.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like the mixed type issue comes from that random X that appears in these columns, there are ints, floats and strings all in the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['CAMEO_DEUG_2015', 'CAMEO_INTL_2015']\n",
    "azdias = mixed_type_fixer(azdias, cols)\n",
    "customers = mixed_type_fixer(customers, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking if values were fixed\n",
    "azdias.CAMEO_DEUG_2015.unique()\n",
    "customers.CAMEO_INTL_2015.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGER_TYP                      5\n",
      "ANREDE_KZ                     2\n",
      "CAMEO_DEU_2015               45\n",
      "CAMEO_DEUG_2015               9\n",
      "CJT_GESAMTTYP                 6\n",
      "D19_BANKEN_DATUM             10\n",
      "D19_BANKEN_OFFLINE_DATUM     10\n",
      "D19_BANKEN_ONLINE_DATUM      10\n",
      "D19_GESAMT_DATUM             10\n",
      "D19_GESAMT_OFFLINE_DATUM     10\n",
      "D19_GESAMT_ONLINE_DATUM      10\n",
      "D19_KONSUMTYP                 7\n",
      "D19_TELKO_DATUM              10\n",
      "D19_TELKO_OFFLINE_DATUM      10\n",
      "D19_TELKO_ONLINE_DATUM       10\n",
      "D19_VERSAND_DATUM            10\n",
      "D19_VERSAND_OFFLINE_DATUM    10\n",
      "D19_VERSAND_ONLINE_DATUM     10\n",
      "D19_VERSI_DATUM              10\n",
      "D19_VERSI_OFFLINE_DATUM      10\n",
      "D19_VERSI_ONLINE_DATUM       10\n",
      "FINANZTYP                     6\n",
      "GEBAEUDETYP                   7\n",
      "GFK_URLAUBERTYP              12\n",
      "GREEN_AVANTGARDE              2\n",
      "KBA05_BAUMAX                  6\n",
      "KK_KUNDENTYP                  6\n",
      "LP_FAMILIE_FEIN              12\n",
      "LP_FAMILIE_GROB               6\n",
      "LP_STATUS_FEIN               10\n",
      "LP_STATUS_GROB                5\n",
      "NATIONALITAET_KZ              4\n",
      "OST_WEST_KZ                   2\n",
      "PLZ8_BAUMAX                   5\n",
      "SHOPPER_TYP                   5\n",
      "SOHO_KZ                       2\n",
      "TITEL_KZ                      6\n",
      "VERS_TYP                      3\n",
      "WOHNLAGE                      8\n",
      "ZABEOTYP                      6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#doing a quick check of categorical features and see if some are too granular to be maintained\n",
    "tst = categorical_checker(azdias, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the categorical info it might be a good idea do drop CAMEO_DEU_2015 column, it is far too fragmented with 45 different category values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_fixer(df, attributes_df):\n",
    "    df.replace({'X': np.nan, 'XX':np.nan, '': np.nan, ' ':np.nan})\n",
    "    #parsing unknown and missing values from the attributes dataframe\n",
    "    m_o_u_list = [x.replace(\"[\",\"\").replace(\"]\",\"\").split(',') for x in attributes_df['missing_or_unknown']]\n",
    "    \n",
    "    #changing strings to floats\n",
    "    m_o_u_float = []\n",
    "    for x in m_o_u_list:\n",
    "        #list inside list\n",
    "        list_of_list = []\n",
    "        for missing in x:\n",
    "            try:\n",
    "                missing = float(missing)\n",
    "                list_of_list.append(missing)\n",
    "            except:\n",
    "                missing = np.nan\n",
    "                list_of_list.append(missing)\n",
    "        list_of_list\n",
    "                \n",
    "        m_o_u_float.append(list_of_list)\n",
    "        \n",
    "        #replacing the missing and unknown values with nan\n",
    "    for col, m_unknown in zip(df.columns, m_o_u_float):\n",
    "        for miss in m_unknown:\n",
    "            df[col].replace(m_unknown, np.nan, inplace = True)\n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>910215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>910220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>910225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>910226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>910241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>910244</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>910248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>910261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>645145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>645153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>645165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>645169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>612558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>612561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>612565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>612569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>612574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>612577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>612586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>612592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>612594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>612595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>612606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>612609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>703164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>703182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>714262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>714263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>714265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>714278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  \\\n",
       "0          NaN  910215       NaN         NaN       NaN          NaN   \n",
       "1          1.0  910220       NaN         9.0       NaN          NaN   \n",
       "2          2.0  910225       NaN         9.0      17.0          NaN   \n",
       "3          3.0  910226       2.0         1.0      13.0          NaN   \n",
       "4          4.0  910241       NaN         1.0      20.0          NaN   \n",
       "5          5.0  910244       3.0         1.0      10.0          NaN   \n",
       "6          6.0  910248       NaN         9.0       NaN          NaN   \n",
       "7          7.0  910261       NaN         1.0      14.0          NaN   \n",
       "8          8.0  645145       NaN         9.0      16.0          NaN   \n",
       "9          9.0  645153       NaN         5.0      17.0          NaN   \n",
       "10        10.0  645165       NaN         1.0      10.0          NaN   \n",
       "11        11.0  645169       NaN         NaN       NaN          NaN   \n",
       "12        12.0  612558       NaN         5.0      21.0          NaN   \n",
       "13        13.0  612561       NaN         8.0      20.0          NaN   \n",
       "14        14.0  612565       NaN         NaN       NaN          NaN   \n",
       "15        15.0  612569       1.0         9.0      11.0          NaN   \n",
       "16        16.0  612574       NaN         1.0      19.0          NaN   \n",
       "17        17.0  612577       NaN         NaN       NaN          NaN   \n",
       "18        18.0  612586       NaN         9.0       NaN          NaN   \n",
       "19        19.0  612592       NaN         9.0       NaN          NaN   \n",
       "20        20.0  612594       NaN         7.0       NaN          NaN   \n",
       "21        21.0  612595       NaN         9.0       NaN          NaN   \n",
       "22        22.0  612606       NaN         8.0       NaN          NaN   \n",
       "23        23.0  612609       NaN         6.0      16.0          NaN   \n",
       "24        24.0  703164       NaN         NaN       NaN          NaN   \n",
       "25        25.0  703182       NaN         1.0      20.0          NaN   \n",
       "26        26.0  714262       NaN         1.0       NaN          NaN   \n",
       "27        27.0  714263       NaN         6.0      16.0         17.0   \n",
       "28        28.0  714265       NaN         9.0      15.0          NaN   \n",
       "29        29.0  714278       2.0         1.0      11.0          NaN   \n",
       "\n",
       "    ALTER_KIND2  ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ...  VHN  \\\n",
       "0           NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "1           NaN          NaN          NaN                  21.0  ...  4.0   \n",
       "2           NaN          NaN          NaN                  17.0  ...  2.0   \n",
       "3           NaN          NaN          NaN                  13.0  ...  0.0   \n",
       "4           NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "5           NaN          NaN          NaN                  10.0  ...  2.0   \n",
       "6           NaN          NaN          NaN                   NaN  ...  2.0   \n",
       "7           NaN          NaN          NaN                  14.0  ...  2.0   \n",
       "8           NaN          NaN          NaN                  16.0  ...  4.0   \n",
       "9           NaN          NaN          NaN                  17.0  ...  4.0   \n",
       "10          NaN          NaN          NaN                  10.0  ...  4.0   \n",
       "11          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "12          NaN          NaN          NaN                  14.0  ...  4.0   \n",
       "13          NaN          NaN          NaN                  20.0  ...  NaN   \n",
       "14          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "15          NaN          NaN          NaN                  11.0  ...  4.0   \n",
       "16          NaN          NaN          NaN                  19.0  ...  1.0   \n",
       "17          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "18          NaN          NaN          NaN                   NaN  ...  0.0   \n",
       "19          NaN          NaN          NaN                   NaN  ...  4.0   \n",
       "20          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "21          NaN          NaN          NaN                   NaN  ...  2.0   \n",
       "22          NaN          NaN          NaN                   NaN  ...  4.0   \n",
       "23          NaN          NaN          NaN                   NaN  ...  2.0   \n",
       "24          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "25          NaN          NaN          NaN                  20.0  ...  2.0   \n",
       "26          NaN          NaN          NaN                   NaN  ...  NaN   \n",
       "27          NaN          NaN          NaN                  16.0  ...  3.0   \n",
       "28          NaN          NaN          NaN                  15.0  ...  3.0   \n",
       "29          NaN          NaN          NaN                  11.0  ...  0.0   \n",
       "\n",
       "    VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0        NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "1        8.0        11.0     10.0             3.0             9.0       4.0   \n",
       "2        9.0         9.0      6.0             3.0             9.0       2.0   \n",
       "3        7.0        10.0     11.0             NaN             9.0       7.0   \n",
       "4        3.0         5.0      4.0             2.0             9.0       3.0   \n",
       "5       10.0         7.0      4.0             6.0             9.0       7.0   \n",
       "6        7.0        10.0     10.0             3.0             9.0       5.0   \n",
       "7       10.0        12.0      9.0             5.0             9.0       1.0   \n",
       "8        8.0        11.0      8.0             5.0             8.0       1.0   \n",
       "9        1.0         1.0      1.0             4.0             3.0       7.0   \n",
       "10       8.0        11.0     10.0             6.0             9.0       5.0   \n",
       "11       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "12       3.0         5.0      3.0             6.0             4.0       3.0   \n",
       "13       3.0         6.0      8.0             6.0             3.0       5.0   \n",
       "14       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "15       6.0         6.0      3.0             6.0             4.0       3.0   \n",
       "16       6.0         9.0      8.0             NaN             3.0       7.0   \n",
       "17       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "18       8.0        11.0     10.0             0.0             5.0       2.0   \n",
       "19       8.0         9.0      6.0             5.0             6.0       1.0   \n",
       "20       8.0        11.0     10.0             3.0             4.0       5.0   \n",
       "21       9.0        11.0      8.0             5.0             9.0       4.0   \n",
       "22       6.0         9.0      7.0             6.0             4.0       4.0   \n",
       "23       3.0         6.0      8.0             3.0             2.0       3.0   \n",
       "24       NaN         NaN      NaN             NaN             NaN       NaN   \n",
       "25       6.0         9.0      7.0             NaN             3.0       7.0   \n",
       "26       7.0         9.0      6.0             3.0             3.0       7.0   \n",
       "27       4.0         7.0      5.0             1.0             3.0       3.0   \n",
       "28       8.0        11.0      8.0             5.0             8.0       5.0   \n",
       "29       9.0        12.0      9.0             6.0             8.0       3.0   \n",
       "\n",
       "    ZABEOTYP ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "0          3         1                     2  \n",
       "1          5         2                     1  \n",
       "2          5         2                     3  \n",
       "3          3         2                     4  \n",
       "4          4         1                     3  \n",
       "5          4         2                     1  \n",
       "6          4         2                     2  \n",
       "7          1         1                     1  \n",
       "8          6         1                     3  \n",
       "9          4         2                     3  \n",
       "10         3         2                     3  \n",
       "11         3         1                     2  \n",
       "12         1         1                     3  \n",
       "13         5         2                     1  \n",
       "14         3         1                     3  \n",
       "15         3         2                     4  \n",
       "16         5         2                     1  \n",
       "17         3         1                     2  \n",
       "18         4         2                     2  \n",
       "19         2         1                     3  \n",
       "20         3         2                     2  \n",
       "21         4         1                     2  \n",
       "22         4         1                     1  \n",
       "23         4         1                     3  \n",
       "24         3         2                     3  \n",
       "25         5         1                     1  \n",
       "26         1         1                     3  \n",
       "27         4         1                     3  \n",
       "28         6         1                     3  \n",
       "29         1         2                     4  \n",
       "\n",
       "[30 rows x 367 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = feat_fixer(azdias, attributes)\n",
    "tester.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(attributes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.missing_or_unknown.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['missing_or_unknown']\n",
    "\n",
    "attributes[cols] = attributes[cols].replace({'X': np.nan, 'XX':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to facilitate deletion and manipulation of rows based on row labels I will set attributes as indexes\n",
    "attributes = attributes.set_index('attribute')\n",
    "\n",
    "#dropping the rows that are problematic (too many feature categories)\n",
    "attributes = attributes.drop('CAMEO_DEU_2015', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias = azdias.drop(['CAMEO_DEU_2015'], axis = 1)\n",
    "customers = customers.drop(['CAMEO_DEU_2015'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is an extra column called Unnamed that seems like an index duplication, I will now drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed column\n",
    "azdias = azdias.drop(azdias.columns[0], axis = 1)\n",
    "customers = customers.drop(customers.columns[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how the azdias dataframe looks like\n",
    "print('Printing dataframe shape')\n",
    "print(azdias.shape)\n",
    "print('________________________________________________________')\n",
    "\n",
    "azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how the customer dataframe looks like\n",
    "print('Printing dataframe shape')\n",
    "print(customers.shape)\n",
    "print('________________________________________________________')\n",
    "\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary csv file\n",
    "print(attributes.shape)\n",
    "attributes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the dataframe shapes:\n",
    "\n",
    "#### For now it is noted that the 2 initial working dataframes had shape discrepancy between them (rows, columns):\n",
    "#### azdias: (891221, 365)\n",
    "#### customers: (191652, 368)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the unique attribute names to lists\n",
    "attributes = attributes.reset_index() \n",
    "attributes_list = attributes.attribute.unique().tolist()\n",
    "azdias_list = list(azdias.columns)\n",
    "customers_list = list(customers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing uniqueness of the attributes accross the datasets in work\n",
    "common_to_all = (set(attributes_list) & set(azdias_list) & set(customers_list))\n",
    "unique_to_azdias = (set(azdias_list) - set(attributes_list) - set(customers_list))\n",
    "unique_to_customers = (set(customers_list) - set(attributes_list) - set(azdias_list))\n",
    "unique_to_attributes = (set(attributes_list) - set(customers_list) - set(azdias_list))\n",
    "unique_to_attributes_vs_azdias = (set(attributes_list) - set(azdias_list))\n",
    "unique_to_azdias_vs_attributes = (set(attributes_list) - set(azdias_list))\n",
    "common_azdias_attributes = (set(azdias_list) & set(attributes_list))\n",
    "\n",
    "print(\"No of items common to all 3 daframes: \" + str(len(common_to_all)))\n",
    "print(\"No of items exclusive to azdias: \" + str(len(unique_to_azdias)))\n",
    "print(\"No of items exclusive to customers: \" + str(len(unique_to_customers)))\n",
    "print(\"No of items exclusive to attributes: \" + str(len(unique_to_attributes)))\n",
    "print(\"No of items overlapping between azdias and attributes: \" + str(len(common_azdias_attributes)))\n",
    "print(\"No of items exclusive to attributes vs azdias: \" + str(len(unique_to_attributes_vs_azdias)))\n",
    "print(\"No of items exclusive to azdias vs attributes: \" + str(len(unique_to_azdias_vs_attributes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8, 8\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor('lightgrey')\n",
    "v = venn2([len(azdias_list), len(attributes_list), len(common_azdias_attributes)], \n",
    "      set_labels=('Azdias', 'Attributes'),\n",
    "         set_colors = ['cyan', 'grey']);\n",
    "\n",
    "plt.title(\"Attribute presence on Azdias vs DIAS Attributes \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this little exploration we got quite a little bit of information:\n",
    "#### - There are 3 extra features in the customers dataset, it corresponds to the columns 'CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'\n",
    "\n",
    "#### - All the datasets share 327 features between them\n",
    "\n",
    "#### - The attributes file has 5 columns corresponding to feature information that does not exist in the other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Now that I have a birds-eye view of the data I will proceed with cleaning and handling missing calues, re-encode features (since the first portion of this project will involve unsupervised learning), perform some feature enginnering and scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing data and replacing it with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking columns missing more than 30% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_azdias_df = percentage_of_missing(azdias)\n",
    "percent_missing_azdias_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_customers_df = percentage_of_missing(customers)\n",
    "percent_missing_customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Empty cells in Azdias dataframe: ', azdias.isnull().sum().sum())\n",
    "print('Empty cells in Customers dataframe: ', customers.isnull().sum().sum())\n",
    "print('________________________________________________________')\n",
    "print(\"Number of Azdias columns not missing values: \", ((percent_missing_azdias_df['percent_missing'] == 0.0).sum()))\n",
    "print(\"Number of Customers columns not missing values: \", ((percent_missing_customers_df['percent_missing'] == 0.0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_missing_over_30 = split_on_percentage(percent_missing_azdias_df, 30, '>')\n",
    "azdias_missing_less_30 = split_on_percentage(percent_missing_azdias_df, 30, '<=')\n",
    "print(azdias_missing_over_30.head())\n",
    "print(azdias_missing_less_30.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_missing_over_30 = split_on_percentage(percent_missing_customers_df, 30, '>')\n",
    "customers_missing_less_30 = split_on_percentage(percent_missing_customers_df, 30, '<=')\n",
    "print(customers_missing_over_30.head())\n",
    "print(customers_missing_less_30.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(4, 1, figsize = (15,15), squeeze = False)\n",
    "\n",
    "azdias_missing_over_30.sort_values(by = 'percent_missing', ascending = False).plot(kind = 'bar', x = 'column_name', y = 'percent_missing',\n",
    "                                                                                ax = axes[0][0], title = 'Azdias percentage of missing values over 30%' )\n",
    "\n",
    "#due to the sheer amount of data points to be plotted this does not make an appealing vis so I will restrict\n",
    "#the number of plotted points to 40\n",
    "azdias_missing_less_30.sort_values(by = 'percent_missing', ascending = False)[:40].plot(kind = 'bar', x = 'column_name', y = 'percent_missing',\n",
    "                                                                                ax = axes[1][0], title = 'Azdias percentage of missing values less 30%' )\n",
    "\n",
    "customers_missing_over_30.sort_values(by = 'percent_missing', ascending = False).plot(kind = 'bar', x = 'column_name', y = 'percent_missing',\n",
    "                                                                                ax = axes[2][0], title = 'Customers percentage of missing values over 30%' )\n",
    "\n",
    "#due to the sheer amount of data points to be plotted this does not make an appealing vis so I will restrict\n",
    "#the number of plotted points to 40\n",
    "customers_missing_less_30.sort_values(by = 'percent_missing', ascending = False)[:40].plot(kind = 'bar', x = 'column_name', y = 'percent_missing',\n",
    "                                                                                ax = axes[3][0], title = 'Customers percentage of missing values less 30%' )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The vast majority of the columns with missing values have a percent of missing under 30% which might means there is some recoverable data.\n",
    "### Based on this information I will remove columns with more than 30% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting column names with more than 30% values missing so we can drop them from azdias df\n",
    "azdias_col_delete = columns_to_delete(azdias_missing_over_30)\n",
    "\n",
    "#extracting column names with more than 30% values missing so we can drop them from customers df\n",
    "customers_col_delete = columns_to_delete(customers_missing_over_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the columns identified in the previous lists\n",
    "\n",
    "azdias = azdias.drop(azdias_col_delete, axis = 1)\n",
    "customers = customers.drop(customers_col_delete, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we dropped columns missing more than 30% of their data it is also important to check the rows (individuals) that have far too much missing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_delete(df, boundary):\n",
    "    '''\n",
    "    This function identifies rows missing more than a particular percentage of data specified with boundary\n",
    "    Args: \n",
    "    dataframe: already cleaned up of columns missing more than a boundary defined percentage \n",
    "    boundary: percentage of missing values\n",
    "    \n",
    "    returns:\n",
    "    dataframe with dropped rows with more than a percentage of missing values\n",
    "    '''\n",
    "    rows_to_drop = list(df[df.isnull().sum(axis = 1) > boundary].index)\n",
    "    print('Rows to drop from this dataframe: ' + str(len(rows_to_drop)))\n",
    "    df_clean_rows = df.drop(rows_to_drop, axis = 0)\n",
    "    \n",
    "    return df_clean_rows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_3 = rows_to_delete(azdias_2, 30)\n",
    "azdias_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
